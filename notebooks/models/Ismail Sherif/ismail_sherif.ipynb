{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, f1_score, recall_score, roc_curve, auc\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import hf_xet\n",
    "\n",
    "import re\n",
    "from textblob import Word\n",
    "from emot.emo_unicode import UNICODE_EMOJI, EMOTICONS_EMO\n",
    "from autocorrect import Speller\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import cycle\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# ---------------------------------------------\n",
    "# run the following only once to download the nltk data\n",
    "# ---------------------------------------------\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# preprocess text function\n",
    "# ---------------------------------------------\n",
    "def preprocess_text(text):\n",
    "    abbreviation_dict = {\n",
    "        \"u\": \"you\", \"bked\": \"booked\", \"thx\": \"thanks\", \"plz\": \"please\",\n",
    "        \"sfo\": \"san francisco airport\", \"lax\": \"los angeles airport\",\n",
    "        \"nyc\": \"new york city\", \"bos\": \"boston\", \"las\": \"las vegas\",\n",
    "        \"dal\": \"dallas\", \"dca\": \"washington, d.c.\", \"lg\": \"likely good\"\n",
    "    }\n",
    "    english_contractions_dict = {\n",
    "        \"ain't\": \"am not\", \"aren't\": \"are not\", \"can't\": \"cannot\", \"can't've\": \"cannot have\",\n",
    "        \"could've\": \"could have\", \"couldn't\": \"could not\", \"couldn't've\": \"could not have\",\n",
    "        \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\",\n",
    "        \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\", \"he'll\": \"he will\",\n",
    "        \"he's\": \"he is\", \"how'd\": \"how did\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "        \"i'd\": \"i would\", \"i'll\": \"i will\", \"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\",\n",
    "        \"it'd\": \"it would\", \"it'll\": \"it will\", \"it's\": \"it is\", \"let's\": \"let us\",\n",
    "        \"ma'am\": \"madam\", \"might've\": \"might have\", \"mightn't\": \"might not\", \"must've\": \"must have\",\n",
    "        \"mustn't\": \"must not\", \"needn't\": \"need not\", \"shan't\": \"shall not\", \"she'd\": \"she would\",\n",
    "        \"she'll\": \"she will\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\",\n",
    "        \"that'd\": \"that would\", \"that's\": \"that is\", \"there's\": \"there is\", \"they'd\": \"they would\",\n",
    "        \"they'll\": \"they will\", \"they're\": \"they are\", \"they've\": \"they have\", \"wasn't\": \"was not\",\n",
    "        \"we'd\": \"we would\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\",\n",
    "        \"what'll\": \"what will\", \"what're\": \"what are\", \"what's\": \"what is\", \"what've\": \"what have\",\n",
    "        \"where's\": \"where is\", \"who's\": \"who is\", \"who've\": \"who have\", \"won't\": \"will not\",\n",
    "        \"would've\": \"would have\", \"wouldn't\": \"would not\", \"you'd\": \"you would\", \"you'll\": \"you will\",\n",
    "        \"you're\": \"you are\", \"you've\": \"you have\"\n",
    "    }\n",
    "    spell = Speller(lang='en')\n",
    "    english_stopwords = stopwords.words(\"english\")\n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'@\\S+', '', text)\n",
    "\n",
    "    words = text.split()\n",
    "    new_words = [abbreviation_dict.get(word, word) for word in words]\n",
    "    text = \" \".join(new_words)\n",
    "\n",
    "    words = text.split()\n",
    "    new_words = [english_contractions_dict.get(word, word) for word in words]\n",
    "    text = \" \".join(new_words)\n",
    "\n",
    "    for emot in UNICODE_EMOJI:\n",
    "        if emot in text:\n",
    "            text = text.replace(\n",
    "                emot,\n",
    "                \" \" + UNICODE_EMOJI[emot].replace(\":\", \"\").replace(\",\", \"\").replace(\"_\", \" \") + \" \"\n",
    "            ).lower()\n",
    "    for emo in EMOTICONS_EMO:\n",
    "        if emo in text:\n",
    "            text = text.replace(\n",
    "                emo,\n",
    "                \" \" + EMOTICONS_EMO[emo].replace(\":\", \"\").replace(\",\", \"\").replace(\"_\", \" \") + \" \"\n",
    "            ).lower()\n",
    "\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = \" \".join(x for x in text.split() if x.lower() not in english_stopwords)\n",
    "    text = ' '.join(spell(word) for word in text.split())\n",
    "    text = \" \".join(Word(word).lemmatize() for word in text.split())\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "\n",
    "# ---------------------------------------------\n",
    "# evaluate model function\n",
    "# ---------------------------------------------\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    train_precision = precision_score(y_train, y_train_pred, average='weighted')\n",
    "    train_recall = recall_score(y_train, y_train_pred, average='weighted')\n",
    "    train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
    "\n",
    "    test_precision = precision_score(y_test, y_test_pred, average='weighted')\n",
    "    test_recall = recall_score(y_test, y_test_pred, average='weighted')\n",
    "    test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "    metrics = {\n",
    "        'Training': {\n",
    "            'Accuracy': train_accuracy * 100,\n",
    "            'Precision': train_precision * 100,\n",
    "            'Recall': train_recall * 100,\n",
    "            'F1-score': train_f1 * 100\n",
    "        },\n",
    "        'Testing': {\n",
    "            'Accuracy': test_accuracy * 100,\n",
    "            'Precision': test_precision * 100,\n",
    "            'Recall': test_recall * 100,\n",
    "            'F1-score': test_f1 * 100\n",
    "        }\n",
    "    }    \n",
    "    print(metrics)\n",
    "    \n",
    "    print(f\"\\nTraining Metrics:\")\n",
    "    print(f\"Accuracy: {train_accuracy*100:.2f}%\")\n",
    "    print(f\"Precision: {train_precision*100:.2f}%\") \n",
    "    print(f\"Recall: {train_recall*100:.2f}%\")\n",
    "    print(f\"F1-Score: {train_f1*100:.2f}%\")\n",
    "    \n",
    "    print(f\"\\nTesting Metrics:\")\n",
    "    print(f\"Accuracy: {test_accuracy*100:.2f}%\")\n",
    "    print(f\"Precision: {test_precision*100:.2f}%\")\n",
    "    print(f\"Recall: {test_recall*100:.2f}%\") \n",
    "    print(f\"F1-Score: {test_f1*100:.2f}%\")\n",
    "    \n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    metrics_train = list(metrics['Training'].values())\n",
    "    metrics_labels = list(metrics['Training'].keys())\n",
    "    ax1.bar(metrics_labels, metrics_train, color=['blue', 'green', 'red', 'purple'])\n",
    "    ax1.set_title('Training Metrics')\n",
    "    ax1.set_ylim(0, 100)\n",
    "    ax1.set_ylabel('Score (%)')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    for i, v in enumerate(metrics_train):\n",
    "        ax1.text(i, v + 1, f'{v:.2f}%', ha='center')\n",
    "        \n",
    "    metrics_test = list(metrics['Testing'].values())\n",
    "    ax2.bar(metrics_labels, metrics_test, color=['blue', 'green', 'red', 'purple'])\n",
    "    ax2.set_title('Testing Metrics')\n",
    "    ax2.set_ylim(0, 100)\n",
    "    ax2.set_ylabel('Score (%)')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    for i, v in enumerate(metrics_test):\n",
    "        ax2.text(i, v + 1, f'{v:.2f}%', ha='center')        \n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_test_pred, labels=['positive', 'negative', 'neutral'])\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['positive', 'negative', 'neutral'], yticklabels=['positive', 'negative', 'neutral'])\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "    y_score = model.predict_proba(X_test)\n",
    "    classes = ['positive', 'negative', 'neutral']\n",
    "    y_test_bin = pd.get_dummies(y_test).values\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(len(classes)):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "    for i, color in zip(range(len(classes)), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=2, label=f'ROC curve for {classes[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curves for Multi-Class Sentiment Analysis')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../../data/clean_Tweets.csv')\n",
    "\n",
    "X = df['text']\n",
    "y = df['airline_sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "# X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "# X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "# w2v_model = Word2Vec(sentences=[text.split() for text in X_train], vector_size=100, window=5, min_count=1, workers=4)\n",
    "# def text_to_vec(text, model):\n",
    "#     words = text.split()\n",
    "#     word_vecs = [model.wv[word] for word in words if word in model.wv]\n",
    "#     if len(word_vecs) == 0:\n",
    "#         return np.zeros(model.vector_size)\n",
    "#     return np.mean(word_vecs, axis=0)\n",
    "# X_train_w2v = np.array([text_to_vec(text, w2v_model) for text in X_train])\n",
    "# X_test_w2v = np.array([text_to_vec(text, w2v_model) for text in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', use_xet=True)\n",
    "model = BertModel.from_pretrained('bert-base-uncased', use_xet=True)\n",
    "\n",
    "def text_to_bert_vec(text, tokenizer, model):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=128)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "\n",
    "# Convert training and testing text to BERT embeddings\n",
    "# This might take a while depending on the dataset size and hardware\n",
    "X_train_bert = np.array([text_to_bert_vec(text, tokenizer, model) for text in X_train])\n",
    "X_test_bert = np.array([text_to_bert_vec(text, tokenizer, model) for text in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling data imbalance\n",
    "smote = SMOTE(random_state=19)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_bert, y_train)\n",
    "\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "# rus = RandomUnderSampler(random_state=42)\n",
    "# X_train_resampled, y_train_resampled = rus.fit_resample(X_train_bert, y_train)\n",
    "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_counts = y_train_resampled.value_counts()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sentiment_counts.plot(kind='bar')\n",
    "plt.xlabel('Airline Sentiment')\n",
    "plt.ylabel('Number of Tweets')\n",
    "plt.title('Distribution of Airline Sentiments')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes_classifier = MultinomialNB()\n",
    "naive_bayes_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "logistic_regression_classifier = LogisticRegression(random_state=42, max_iter=1000)\n",
    "logistic_regression_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "support_vector_machine_classifier = SVC(kernel='linear', random_state=42)\n",
    "support_vector_machine_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "lr_classifier = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_classifier.fit(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"great flight amazing service\"\n",
    "text = \"worst flight ever\"\n",
    "text = \"I am going to my school\"\n",
    "\n",
    "text_tokenized = preprocess_text(text)\n",
    "text_tfidf = vectorizer.transform([text])\n",
    "prediction = nb_classifier.predict(text_tfidf)\n",
    "\n",
    "print(f\"\\nExample Tweet: '{text}'\")\n",
    "print(f\"Predicted Sentiment: {prediction[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
